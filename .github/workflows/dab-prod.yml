name: DAB Deploy + Run (Prod)

on:
  push:
    tags:
      - "v*"
  workflow_dispatch:
    inputs:
      run_bootstrap:
        description: "Run bootstrap (Create UC/Schemas)"
        type: boolean
        default: false
      run_jobs:
        description: "Run ingest/pipeline after deploy?"
        type: boolean
        default: false
      run_pipelines:
        description: "Run pipeline after deploy?"
        type: boolean
        default: false

jobs:
  deploy-prod:
    runs-on: ubuntu-latest

    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - uses: actions/checkout@v4

      - name: Install Databricks CLI
        uses: databricks/setup-cli@main

      # --- BOOTSTRAP (Infrastructure) ---
      - name: Deploy and run bootstrap for PROD
        run: |
          # Swap to bootstrap config
          mv databricks.yml app_config_backup.yml
          mv bootstrap.yml databricks.yml
          
          # Run using the "default" file
          databricks bundle deploy -t prod --auto-approve
          databricks bundle run bootstrap_uc -t prod
          
          # Swap back to app config
          mv databricks.yml bootstrap.yml
          mv app_config_backup.yml databricks.yml
      
      # --- DEPLOY PROD ---
      - name: Validate prod target
        run: databricks bundle validate -t prod

      - name: Deploy prod target
        run: databricks bundle deploy -t prod --auto-approve

      # --- RUN WORKFLOWS ---
      - name: Run main prod jobs
        if: github.event.inputs.run_jobs == 'true'
        run: |
          databricks bundle run get_met_stations -t prod
          databricks bundle run ingest_update_met -t prod

      - name: Run main prod pipelines
        if: github.event.inputs.run_pipelines == 'true'
        run: |
          databricks bundle run airquality_pipeline -t prod